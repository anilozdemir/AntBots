{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# antBot Highway World Experiments: EMB\n",
    "Run EMB on antBot Highway World Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as P\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from pyRC.analyse.perfectMemory import *\n",
    "\n",
    "# Plotting settings\n",
    "sns.set_context(\"notebook\", font_scale = 1.5)\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"deep\", 12)\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "cmap='Greys_r'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from pyRC.datasets.utils import ImageDataset\n",
    "\n",
    "class antBotDatasets():\n",
    "    def __init__(self, expPath = '../data/2000-10/'):\n",
    "        self.expPath     = expPath # experiment path\n",
    "        self.HW          = [[75,360], [50,180], [25,90]] # (h,w) pairs FIXED for now\n",
    "        self.strImages   = sorted([f.replace('.npy','') for f in listdir(self.expPath)])# get the name of all data in the given experiment path\n",
    "        self.allImages   = np.stack([np.load(self.expPath+f+'.npy') for f in self.strImages]) # load all the data matched in strImages\n",
    "        self.nDatasets   = self.allImages.shape[0]\n",
    "        self.nImages     = self.allImages.shape[1]\n",
    "        self.HW_Original = self.allImages.shape[-2:]\n",
    "        self.nHW         = len(self.HW)\n",
    "        print(f'>> Loaded {self.nDatasets} datasets of {self.nImages} images each!')\n",
    "        \n",
    "#         self.allImagesTorch = torch.Tensor(self.allImages)\n",
    "\n",
    "    def setGT(self, strGT = 'mountains'):\n",
    "        #TODO try except error throw if strGT is not in list\n",
    "        self.strGT    = strGT # ground truth name\n",
    "        self.gtImages = self.allImages[self.strImages.index(strGT)] # find the index of the gtName in the list of names first\n",
    "        print(f'>> Set `{self.strGT}` as ground truth!')\n",
    "    \n",
    "    \n",
    "    def get(self, strDataset = 'mountains', nImages=200, h=25, w=90):\n",
    "        # dataSet in shape: torch.Size([num_images, height, width, batchSize=1]) # batchSize=1 reserved for batch, to be permuted to top\n",
    "        dsID    = self.strImages.index(strDataset)\n",
    "        Images0 = self.allImages[dsID]\n",
    "        Images  = np.stack([IMAGEOP(img,h,w) for img in Images0]) # need to swap axis of height(2) and width(1)\n",
    "        ImagesT = torch.Tensor(Images).permute(0,2,1).unsqueeze(-1) # add dimension for batch operations\n",
    "        iLabels = range(self.nImages)\n",
    "        dataSet                = ImageDataset(ImagesT, iLabels)\n",
    "        dataLoader             = DataLoader(dataSet, batch_size = 1, shuffle = False)\n",
    "        dataLoader.nInput      = h*w   # image height is the number of inputs\n",
    "        dataLoader.nOutput     = nImages # nImages to choose from\n",
    "        dataLoader.groundTruth = iLabels\n",
    "        return dataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loaded 7 datasets of 200 images each!\n"
     ]
    }
   ],
   "source": [
    "ds = antBotDatasets()\n",
    "DL = ds.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PyTorch-Lightning Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.classification import ConfusionMatrix\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import pyRC.datasets.nordland as Nordland\n",
    "import pyRC.learn.utils       as utL\n",
    "import pyRC.network as RC\n",
    "import pyRC.analyse.utils as utA\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as P\n",
    "P.style.use('seaborn-dark')\n",
    "\n",
    "class antBotEMB(LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hparams = {**config['hyperparameters'], **config['experimentParameters'], **config['modelParameters'], **config['experimentDetails']} # unzip nested dict\n",
    "        self.dlargs  = {'nImages': self.hparams['nImages'], 'h': self.hparams['height'], 'w': self.hparams['width']}\n",
    "        self.RC      = RC.ESN_NA(self.hparams, readoutType=self.hparams['readoutType'])\n",
    "        print('>> Network is constructed!')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.RC(x)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        antBotData              = antBotDatasets()\n",
    "        self.data_0             = antBotData.get('dawn_cloudy_empty'  , **self.dlargs)\n",
    "        self.data_1             = antBotData.get('dusk'  , **self.dlargs)\n",
    "        self.data_2             = antBotData.get('mountains'  , **self.dlargs)\n",
    "        self.GroundTruth        = torch.Tensor(self.data_0.groundTruth)\n",
    "        self.hparams['nParams'] = utA.modelParameters(self.RC, returnOnly=True).item()\n",
    "        print('>> Datasets are loaded!')\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return self.data_0\n",
    "      \n",
    "    def test_dataloader(self):\n",
    "        return [self.data_0, self.data_1, self.data_2]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        params = [{'params': self.RC.Wout, 'lr': self.hparams['learningRate']}] \n",
    "        return torch.optim.Adam(params)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        if batch_idx == 0:  # At the beginning of each epoch, reset the model! \n",
    "            self.RC.reset()\n",
    "            \n",
    "        x, y  = batch\n",
    "        y_hat = self(x)\n",
    "        loss  = F.cross_entropy(y_hat, y)\n",
    "        logs_loss = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs_loss}\n",
    "\n",
    "    def test_step(self, batch, batch_idx, dataloader_idx): \n",
    "        #TODO implement error instead of loss! torch.mean(abs(df['imageID']-df['predIDF']))\n",
    "        x, y    = batch\n",
    "        y_hat   = self(x)\n",
    "        tol_acc = (torch.abs(self.GroundTruth[batch_idx] - torch.argmax(y_hat))<self.hparams['tolerance']) # Accuracy\n",
    "        return {'test_loss': F.cross_entropy(y_hat, y), 'tol_acc': tol_acc, 'y_pred': y_hat}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        loss_0 = torch.stack([x['test_loss'] for x in outputs[0]]).mean()\n",
    "        loss_1 = torch.stack([x['test_loss'] for x in outputs[1]]).mean()\n",
    "        loss_2 = torch.stack([x['test_loss'] for x in outputs[2]]).mean()\n",
    "        \n",
    "        acc_0  = torch.stack([x['tol_acc'] for x in outputs[0]]).float().mean()*100 # percentage\n",
    "        acc_1  = torch.stack([x['tol_acc'] for x in outputs[1]]).float().mean()*100 # percentage\n",
    "        acc_2  = torch.stack([x['tol_acc'] for x in outputs[2]]).float().mean()*100 # percentage\n",
    "        \n",
    "        logs_loss   = {'loss_0': loss_0, 'loss_1': loss_1, 'loss_2': loss_2}\n",
    "        logs_acc    = {'acc_0' : acc_0,  'acc_1' : acc_1 , 'acc_2': acc_2}\n",
    "        return {'log': {**logs_loss, **logs_acc}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | RC   | ESN_NA | 800 K \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loaded 7 datasets of 200 images each!\n",
      ">> Datasets are loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafcf12bffde4fac8ebe261f30b999d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Loaded 7 datasets of 200 images each!\n",
      ">> Datasets are loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbe450b8ab34a7d88968a7d69b75a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'acc_0': tensor(88., device='cuda:0'),\n",
      " 'acc_1': tensor(30.0000, device='cuda:0'),\n",
      " 'acc_2': tensor(20.0000, device='cuda:0'),\n",
      " 'loss_0': tensor(1.9518, device='cuda:0'),\n",
      " 'loss_1': tensor(4.9857, device='cuda:0'),\n",
      " 'loss_2': tensor(6.5184, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ## Training\n",
    "config = utL.getConfig('config.yaml')\n",
    "\n",
    "config['hyperparameters']['nReservoir']  = 4000\n",
    "config['experimentParameters']['nEpoch'] = 100\n",
    "config['experimentDetails']['width']     = 360\n",
    "config['experimentDetails']['height']    = 25\n",
    "config['modelParameters']['nInput']      = config['experimentDetails']['width'] * config['experimentDetails']['height']\n",
    "\n",
    "expDict = {\n",
    "            'gpus'                     : 1,\n",
    "            'profiler'                 : False,\n",
    "            'log_save_interval'        : 10000,\n",
    "            'progress_bar_refresh_rate': 100,\n",
    "            'row_log_interval'         : 10000,\n",
    "            'max_epochs'               : config['experimentParameters']['nEpoch'],\n",
    "            }\n",
    "            \n",
    "exp     = antBotEMB(config)\n",
    "trainer = Trainer(**expDict)\n",
    "trainer.fit(exp); \n",
    "trainer.test(ckpt_path=None);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
